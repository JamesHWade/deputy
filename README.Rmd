---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  eval = FALSE
)
```

# deputy

<!-- badges: start -->
[![R-CMD-check](https://github.com/JamesHWade/deputy/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/JamesHWade/deputy/actions/workflows/R-CMD-check.yaml)
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
<!-- badges: end -->
deputy is an agentic AI framework for R built on [ellmer](https://ellmer.tidyverse.org/). It enables you to create AI agents that can use tools to accomplish multi-step tasks, with built-in support for permissions, hooks, and streaming output.

## Features
- **Provider-agnostic** - Works with OpenAI, Anthropic, Google, Ollama, and any provider ellmer supports
- **Tool bundles** - Pre-built tools for file operations, code execution, and data analysis
- **Permission system** - Fine-grained control over what agents can do
- **Hooks** - Intercept and customize agent behavior at key points
- **Streaming output** - Real-time feedback as agents work
- **Multi-agent** - Coordinate specialized sub-agents for complex tasks
- **Session persistence** - Save and restore agent conversations

## Installation

You can install the development version of deputy from GitHub:
```r
# install.packages("pak")
pak::pak("JamesHWade/deputy")
```

You'll also need ellmer:

```r
pak::pak("tidyverse/ellmer")
```

## Quick Start

### Create an Agent

```{r example}
library(deputy)

# Create an agent with file tools
agent <- Agent$new(
  chat = ellmer::chat("openai/gpt-4o"),
  tools = tools_file()
)

# Run a task (blocking)
result <- agent$run_sync("What R files are in the current directory?")
cat(result$response)
```

### Streaming Output

For real-time feedback as the agent works:

```{r streaming}
for (event in agent$run("Analyze the structure of this project")) {
  switch(event$type,
    "text" = cat(event$text),
    "tool_start" = message("Calling ", event$tool_name, "..."),
    "stop" = message("\nDone! Cost: $", round(event$cost$total, 4))
  )
}
```

### Tools

deputy provides convenient tool bundles:

```{r tools}
# File operations: read_file, write_file, list_files
tools_file()

# Code execution: run_r_code, run_bash
tools_code()

# Data reading: read_csv, read_file
tools_data()

# All built-in tools
tools_all()
```

### Permissions

Control what your agent can do:

```{r permissions}
# Read-only: no writes, no code execution
agent <- Agent$new(

  chat = ellmer::chat("openai/gpt-4o"),
  tools = tools_file(),
  permissions = permissions_readonly()
)

# Standard: file read/write in working dir, R code, no bash
agent <- Agent$new(
 chat = ellmer::chat("openai/gpt-4o"),
  tools = tools_file(),
  permissions = permissions_standard()
)

# Custom permissions with limits
agent <- Agent$new(
  chat = ellmer::chat("openai/gpt-4o"),
  tools = tools_all(),
  permissions = Permissions$new(
    file_write = getwd(),
    bash = FALSE,
    r_code = TRUE,
    max_turns = 10,
    max_cost_usd = 0.50
  )
)
```

### Hooks

Intercept agent behavior:

```{r hooks}
# Log all tool calls
agent$add_hook(HookMatcher$new(
  event = "PostToolUse",
  callback = function(tool_name, tool_result, context) {
    message("[", Sys.time(), "] ", tool_name)
    HookResultPostToolUse()
  }
))

# Block dangerous bash commands
agent$add_hook(HookMatcher$new(
  event = "PreToolUse",
  pattern = "^run_bash$",
  callback = function(tool_name, tool_input, context) {
    if (grepl("rm -rf|sudo", tool_input$command)) {
      HookResultPreToolUse(permission = "deny", reason = "Dangerous command")
    } else {
      HookResultPreToolUse(permission = "allow")
    }
  }
))
```

### Multi-Agent Systems

Coordinate specialized agents:

```{r multi-agent}
# Define sub-agents
code_agent <- agent_definition(
  name = "code_analyst",
  description = "Analyzes R code",
  prompt = "You are an expert R programmer.",
  tools = tools_file()
)

# Create lead agent that can delegate
lead <- LeadAgent$new(
  chat = ellmer::chat("openai/gpt-4o"),
  sub_agents = list(code_agent)
)

result <- lead$run_sync("Review the R code in this project")
```

## Provider Support

deputy works with any LLM provider that ellmer supports:

```{r providers}
# OpenAI
Agent$new(chat = ellmer::chat("openai/gpt-4o"))

# Anthropic
Agent$new(chat = ellmer::chat("anthropic/claude-sonnet-4-5-20250929"))

# Google
Agent$new(chat = ellmer::chat("google/gemini-1.5-pro"))

# Local via Ollama
Agent$new(chat = ellmer::chat("ollama/llama3.1"))
```

## Learn More

- `vignette("getting-started")` - Comprehensive introduction
- [ellmer documentation](https://ellmer.tidyverse.org/) - Underlying LLM framework

## License

MIT
